{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [o, t, h, e, r,  , w, o, r, d,  , k, a, t, a, ...\n",
       "1        [a, u, s, s, i, e, t, v,  , w, h, i, t, e,  , ...\n",
       "2        [c, l, a, s, s, i,  , w, h, o, r, e,  , m, o, ...\n",
       "3        [_, g, i, o,  , m, e, h,  , t, h, a, n, k,  , ...\n",
       "4        [t, h, i,  , i, s, i,  , a, c, c, o, u, n, t, ...\n",
       "                               ...                        \n",
       "47687    [b, l, a, c, k,  , a, r, e, n,  , t,  , e, x, ...\n",
       "47688    [t, u, r, n, e, r,  , w, i, t, h, h, o, l, d, ...\n",
       "47689    [s, w, e, a, r,  , g, o, d,  , t, h, i,  , d, ...\n",
       "47690    [f, u, c, k,  , y, o, u, r,  , n, i, g, g, e, ...\n",
       "47691    [b, r, o,  , g, o, t, t, a,  , c, h, i, l, l, ...\n",
       "Name: tweet_text, Length: 47692, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = pd.read_csv(r'/home/chinchu/Desktop/Cyber bullying_tweets/cyberbullying_tweets.csv')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def clear(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+','',text)\n",
    "    text = re.sub(r'RT[\\s]+','',text)\n",
    "    text = re.sub(r'https?:\\/\\/\\S+','',text)\n",
    "    text = re.sub(r'#','',text)\n",
    "\n",
    "    return text\n",
    "\n",
    "d1['tweet_text'] = d1['tweet_text'].apply(clear)\n",
    "d1['tweet_text'] = d1['tweet_text'].str.replace(\"[^a-zA-Z@]\",' ')\n",
    "\n",
    "d1['tweet_text'] = d1['tweet_text'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "d1['tweet_text'] = d1['tweet_text'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def word_stemmer(text):\n",
    "    stem_text = \" \".join([stemmer.stem(i) for i in text])\n",
    "    return stem_text\n",
    "\n",
    "d1['tweet_text'] = d1['tweet_text'].apply(lambda x: word_stemmer(x))\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def word_lemmatizer(text):\n",
    "    lem_text = [lemmatizer.lemmatize(i) for i in text]\n",
    "    return lem_text\n",
    "\n",
    "d1['tweet_text'].apply(lambda x: word_lemmatizer(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>other word katandandr your food crapilici</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aussietv white theblock imacelebrityau today s...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>classi whore more velvet cupcak</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_gio meh thank head concern about anoth angri ...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thi isi account pretend kurdish account like i...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text cyberbullying_type\n",
       "0          other word katandandr your food crapilici  not_cyberbullying\n",
       "1  aussietv white theblock imacelebrityau today s...  not_cyberbullying\n",
       "2                    classi whore more velvet cupcak  not_cyberbullying\n",
       "3  _gio meh thank head concern about anoth angri ...  not_cyberbullying\n",
       "4  thi isi account pretend kurdish account like i...  not_cyberbullying"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3035"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1['tweet_text'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.drop_duplicates('tweet_text', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1['cyberbullying_type'] = d1['cyberbullying_type'].replace(to_replace=['gender','other_cyberbullying','age','ethnicity'],value = 'Bullying')\n",
    "d1['cyberbullying_type'] = d1['cyberbullying_type'].map({'not_cyberbullying':0,'Bullying':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8817/2852598885.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  d1['cyberbullying_type'].fillna(0,inplace=True)\n",
      "/tmp/ipykernel_8817/2852598885.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  d1['tweet_text'].fillna('',inplace=True)\n"
     ]
    }
   ],
   "source": [
    "d1['cyberbullying_type'].fillna(0,inplace=True)\n",
    "d1['tweet_text'].fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40191, 5000)\n",
      "(4466, 5000)\n"
     ]
    }
   ],
   "source": [
    "X = d1['tweet_text']  \n",
    "y = d1['cyberbullying_type'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features = 5000)\n",
    "X_train_tf = tfidf.fit_transform(X_train)\n",
    "X_test_tf = tfidf.transform(X_test)  \n",
    "\n",
    "print(X_train_tf.shape)\n",
    "print(X_test_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tfidf_vectorization','wb') as f:\n",
    "    pickle.dump(tfidf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logic = LogisticRegression()\n",
    "logic.fit(X_train_tf,y_train)\n",
    "pred = logic.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model','wb') as f:\n",
    "    pickle.dump(logic,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
